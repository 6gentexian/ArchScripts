#####################################################################
#  Download and install common packages
if [ -f ~/pacman_installed_pkglist.txt ]; then
  mv ~/pacman_installed_pkglist.txt $SRC_CONFIG_DIR
  fi

while read -u10 p; do
  echo "tester: $p"
  done 10< $SRC_CONFIG_DIR"/pacman_installed_pkglist.txt"

#####################################################################

Solid State Drives (SSDs) are not PnP devices. Special considerations such as partition alignment, choice of file system, TRIM support, etc. are needed to set up SSDs for optimal performance.

There are several key features to look for prior to purchasing a contemporary SSD.

Native TRIM support is a vital feature that both prolongs SSD lifetime and reduces loss of performance for write operations over time.
Buying the right sized SSD is key. As with all filesystems, target <75 % occupancy for all SSD partitions to ensure efficient use by the kernel.

Partition alignment

Proper partition alignment is essential for optimal performance and longevity. This is due to the block nature of every I/O operation on the hardware level as well as file system level. The key to alignment is partitioning to (at least) the given block size, which depends on the used hardware. If the partitions are not aligned to begin at multiples of the block size, aligning the file system is a pointless exercise because everything is skewed by the start offset of the partition.

Partitioning tools

In past, proper alignment required manual calculation and intervention when partitioning. Many of the common partition tools now handle partition alignment automatically:

fdisk
gdisk
gparted
parted
To verify a partition is aligned, query it using /usr/bin/blockdev as shown below, if a '0' is returned, the partition is aligned:

# blockdev --getalignoff /dev/<partition>
0


TRIM
Most SSDs support the ATA_TRIM command for sustained long-term performance and wear-leveling. For more including some before and after benchmark, see this tutorial.
As of linux kernel version 3.7, the following filesystems support TRIM: Ext4, Btrfs, JFS, VFAT, XFS, F2FS.
VFAT only supports TRIM by Mount Flag 'discard', not by fstrim.
The Choice of Filesystem section of this article offers more details.
Verify TRIM Support
# hdparm -I /dev/sda | grep TRIM
        *    Data Set Management TRIM supported (limit 1 block)
	Note that there are different types of TRIM support defined by the specification. Hence, the output may differ depending what the drive supports. See wikipedia:TRIM#ATA for more information.
	Enable TRIM by Mount Flags
	Using this flag in one's /etc/fstab enables the benefits of the TRIM command stated above.
	/dev/sda1  /       ext4   defaults,noatime,discard   0  1
	/dev/sda2  /home   ext4   defaults,noatime,discard   0  2
	Note:
	TRIM is not by default activated when using block-device encryption on a SSD; for more information see Dm-crypt/TRIM support for SSD.
	There is no need for the discard flag if you run fstrim periodically.
	Using the discard flag for an ext3 root partition will result in it being mounted read-only.
	Warning: Users need to be certain that their SSD supports TRIM before attempting to mount a partition with the discard flag. Data loss can occur otherwise!

I/O Scheduler

Consider switching from the default CFQ scheduler (Completely Fair Queuing) to NOOP or Deadline. The latter two offer performance boosts for SSDs.

The CFQ scheduler is enabled by default on Arch. Verify this by viewing the contents /sys/block/sdX/queue/scheduler:
$ cat /sys/block/sdX/queue/scheduler
noop deadline [cfq]
The scheduler currently in use is denoted from the available schedulers by the brackets.

Using udev for one device or HDD/SSD mixed environment
Though the above will undoubtedly work, it is probably considered a reliable workaround. Ergo, it would be preferred to use the system that is responsible for the devices in the first place to implement the scheduler. In this case it is udev, and to do this, all one needs is a simple udev rule.
To do this, create the following:
/etc/udev/rules.d/60-schedulers.rules
# set deadline scheduler for non-rotating disks
ACTION=="add|change", KERNEL=="sd[a-z]", ATTR{queue/rotational}=="0", ATTR{queue/scheduler}="deadline"
Of course, set Deadline/CFQ to the desired schedulers. Changes should occur upon next boot. To check success of the new rule:
$ cat /sys/block/sdX/queue/scheduler  # where X is the device in question
Note: In the example sixty is chosen because that is the number udev uses for its own persistent naming rules. Thus, it would seem that block devices are at this point able to be modified and this is a safe position for this particular rule. But the rule can be named anything so long as it ends in .rules.)
Swap Space on SSDs
One can place a swap partition on an SSD. Most modern desktops with an excess of 2 Gigs of memory rarely use swap at all. The notable exception is systems which make use of the hibernate feature.
A recommended tweak for SSDs using a swap partition is to reduce the swappiness of the system to some very low value (for example 1), and thus avoiding writes to swap.



SSD Memory Cell Clearing
On occasion, users may wish to completely reset an SSD's cells to the same virgin state they were at the time the device was installed thus restoring it to its factory default write performance. Write performance is known to degrade over time even on SSDs with native TRIM support. TRIM only safeguards against file deletes, not replacements such as an incremental save.
The reset is easily accomplished in a three step procedure denoted on the SSD memory cell clearing wiki article.
Tips for minimizing disk reads/writes

An overarching theme for SSD usage should be 'simplicity' in terms of locating high-read/write operations either in RAM (Random Access Memory) or on a physical HDD rather than on an SSD. Doing so will add longevity to an SSD. This is primarily due to the large erase block size (512 KiB in some cases); a lot of small writes result in huge effective writes.
Note: A 32GB SSD with a mediocre 10x write amplification factor, a standard 10000 write/erase cycle, and 10GB of data written per day, would get an 8 years life expectancy. It gets better with bigger SSDs and modern controllers with less write amplification. Also compare [7] when considering whether any particular strategy to limit disk writes is actually needed.
Use iotop and sort by disk writes to see how much and how frequently are programs writing to the disk.



Intelligent partition scheme
For systems with both an SSD and an HDD, consider relocating the /var partition to a magnetic disc on the system rather than on the SSD itself to avoid read/write wear.
noatime mount option

Using this flag in one's /etc/fstab halts the logging of read accesses to the file system via an update to the atime information associated with the file. The importance of the noatime setting is that it eliminates the need by the system to make writes to the file system for files which are simply being read.

If desirable, enable the "discard" filesystem options for automatic/online TRIM.

Set "discard" mount option in /etc/fstab for the ext4 filesystem, swap partition, Btrfs, etc. See mount(8).
Set "issue_discards" option in /etc/lvm/lvm.conf for LVM. See lvm.conf(5).
Set "discard" option in /etc/crypttab for dm-crypt.
See http://blog.neutrino.es/2013/howto-properly-activate-trim-for-your-ssd-on-linux-fstrim-lvm-and-dmcrypt/

The "discard" options is not needed if your SSD has enough overprovisioning (spare space) or you leave (unpartitioned) free space on the SSD.

See http://www.spinics.net/lists/raid/msg40866.html



Locate frequently used files to RAM
Browser profiles
One can easily mount browser profile(s) such as chromium, firefox, opera, etc. into RAM via tmpfs and also use rsync to keep them synced with HDD-based backups. In addition to the obvious speed enhancements, users will also save read/write cycles on their SSD by doing so.
The AUR contains several packages to automate this process, for example profile-sync-daemon.

reduce swapping activities with ZRam

Using ZRam (aka compcache) it is possible to use data compression on the contents of the system memory (RAM). This effectively trades in some CPU cycles for the ability to stuff a lot more into the available system memory and thereby reduces the need for swapping out memory pages to the SSD. It uses specialised high speed data compression algorithms that are especially light on the CPU and yet are said to give typically about 1:3 compression on this type of content. Because compressing is typically faster than writing to swap devices it also brings performance improvements to systems without excessive amounts of physical memory. It is available starting with version 3.2 of the Linux kernel. See the respective article on how to activate it, if you have a matching kernel version.



AHCI is Required!

SSD trim support is very important! The Linux kernel requires the SATA controller set to AHCI mode to use trim support.

Prepare FSTAB Entries

You should prepare the new FSTAB entries before copying a source drive to avoid copying data moved to tmpfs. Changes made to this system include:
Added discard to the ext4 file system to activate SSD trim support.
Added noatime to reduce writes, note that it is known some applications have problems with this but they are rare.
Added nodiratime to reduce writes.
Moved some directories to tmpfs.
Created /ramdisk for Firefox cache but could have used Firefox config to replace disk cache with memory cache.
This is the FSTAB used, the first six are the SSD partitions:
 LABEL=SSDsuse121     /                    ext4 acl,noatime,nodiratime,discard   1 1
  LABEL=SSDsuse121m    /suse121m            ext4 acl,noatime,nodiratime,discard   0 2
   LABEL=SSDcommon      /common              ext4 acl,noatime,nodiratime,discard   0 2
    LABEL=SSDsuse122m    /suse122m            ext4 acl,noatime,nodiratime,discard   0 2
     LABEL=SSDgrub        /grub                ext4 noacl,noatime,nodiratime,discard 0 2
      LABEL=SSDswap        swap                 swap defaults              0 0
       proc                 /proc                proc defaults              0 0
        sysfs                /sys                 sysfs noauto               0 0
	 debugfs              /sys/kernel/debug    debugfs noauto             0 0
	  usbfs                /proc/bus/usb        usbfs noauto               0 0
	   devpts               /dev/pts             devpts mode=0620,gid=5     0 0
	    tmpfs                /ramdisk             tmpfs nodev,nosuid,noatime,mode=1777,size=100M 0 0
	     tmpfs                /tmp                 tmpfs defaults,noatime,mode=1777   0  0
	      tmpfs                /var/spool           tmpfs defaults,noatime,mode=1777   0  0
	       tmpfs                /var/tmp             tmpfs defaults,noatime,mode=1777   0  0
	        #  .thumbnails files are never deleted and can grow quite large over time.
		 tmpfs                /root/.thumbnails    tmpfs defaults,noatime,mode=1777   0  0
		  tmpfs                /home/mario/.thumbnails    tmpfs defaults,noatime,mode=1777   0  0
		  Swappiness

This only applies if the swap file is moved to the SSD. The swappiness value affects the activity of the swap file. If you placed the swap file on the SSD you should reduce the swappiness of Linux. There are many good explanations but simply put: Linux tries to anticipate when something might need to be swapped and does it anyway. By reducing swappiness Linux is less likely to do this so swap writes are reduced. Swappiness is a value from 0 to 100, the higher the more swappiness. You can check your current value using:

   cat /proc/sys/vm/swappiness
   There are a couple of different ways to change swappiness permanently. I changed this system from it's default of 60 to 1 by adding the following to /etc/sysctl.conf:

   vm.swappiness=1
      vm.vfs_cache_pressure=50
      Research showed that reducing swappiness when using HDDs also resulted in better performance.

Never Do This!

Never perform defragmentation, it serves no purpose but to increase SSD wear and slow it down.


Zram or zswap

The zram kernel module (previously called compcache) provides a compressed block device in RAM. If you use it as swap device, the RAM can hold much more information but uses more CPU. Still, it is much quicker than swapping to a hard drive. If a system often falls back to swap, this could improve responsiveness.

Example: To set up one lz4 compressed zram device with 32GiB capacity and a higher-than-normal priority (only for the current session):

# modprobe zram
# echo lz4 > /sys/block/zram0/comp_algorithm
# echo 32G > /sys/block/zram0/disksize
# mkswap --label zram0 /dev/zram0
# swapon --priority 100 /dev/zram0
To disable it again, either reboot or run

# swapoff /dev/zram0
# rmmod zram
If you want to automatically initialize zram on every boot, consider writing a systemd service for it.

A detailed explanation of all steps, options and potential problems is provided in the official documentation of the module here.

The AUR package zramswap provides an automated script for setting up such swap devices with optimal settings for your system (such as RAM size and CPU core number). The script creates one zram device per CPU core with a total space equivalent to the RAM available. To do this automatically on every boot, enable zramswap.service via systemctl.

=================================================

=================================================



